# -*- coding: utf-8 -*-
"""
KM íŒŒì´í”„ë¼ì¸(ì£¼ê°„):
- ë§¤ì£¼ ì¼ìš”ì¼ 23:59 (Asia/Seoul) ê¸°ì¤€
1) new_lecture â†’ lvt_log (INSERT: ì—´ë¦° episode ì—†ì„ ë•Œë§Œ)
2) pause_lecture â†’ lvt_log (UPDATE: ì—´ë¦° episodeë§Œ end_date ì„¸íŒ…)
3) weekly_actuals ì§‘ê³„/ì—…ì„œíŠ¸ (ì›”~ì¼)
4) KM ì¬í•™ìŠµ (as-of = ì¼ìš”ì¼, lvt_log ê¸°ë°˜ ê²€ì—´ í¬í•¨)
5) model_versions í™œì„±í™” ë¡¤ì˜¤ë²„(ê°™ì€ ì°½/ë‹¨ìœ„ upsert)

ì—°ê²°: postgres_conn_2.0
"""

from datetime import datetime, timedelta
import pendulum
from airflow.decorators import dag, task
from airflow.providers.postgres.hooks.postgres import PostgresHook

import pandas as pd
import numpy as np

# -----------------------------
# ì„¤ì •
# -----------------------------
SEOUL = pendulum.timezone("Asia/Seoul")
CONN_ID = "postgres_conn_2.0"

# ì¬í•™ìŠµ ì°½: ìµœê·¼ 12ê°œì›”(í•„ìš”ì‹œ ë°”ê¾¸ì„¸ìš”)
FIT_MONTHS = 12
# KM horizon (ì£¼) â€” í•„ìš”ì‹œ ë°”ê¾¸ì„¸ìš”
HORIZON_WEEKS = 52

# -----------------------------
# ìœ í‹¸
# -----------------------------
def _week_bounds_kst(now_ts: pendulum.DateTime):
    """í•´ë‹¹ ì£¼ ì›”~ì¼ê¹Œì§€ ë²”ìœ„(ë‚ ì§œ ë¬¸ìì—´)"""
    week_end = now_ts.end_of("week")     # ì¼ìš”ì¼ 23:59:59
    week_start = week_end.start_of("week")  # ì›”ìš”ì¼ 00:00:00
    return week_start.date().isoformat(), week_end.date().isoformat()

def _ensure_weekly_actuals(hook: PostgresHook):
    # 1) í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´). ìŠ¤í‚¤ë§ˆ ëª…ì‹œ!
    hook.run("""
    CREATE TABLE IF NOT EXISTS kpis.weekly_actuals (
      week_start date NOT NULL,
      cohort_months integer NOT NULL,
      new_actual integer NOT NULL DEFAULT 0,
      pause_actual integer NOT NULL DEFAULT 0,
      source varchar(32),
      closed_at timestamptz
    );
    """)

    # 2) ê¸°ì¡´ í…Œì´ë¸”ì— cohort_months ì—†ê±°ë‚˜ NULLì´ë©´ ë³´ì •
    hook.run("ALTER TABLE kpis.weekly_actuals ADD COLUMN IF NOT EXISTS cohort_months integer;")
    hook.run("UPDATE kpis.weekly_actuals SET cohort_months = 0 WHERE cohort_months IS NULL;")
    hook.run("ALTER TABLE kpis.weekly_actuals ALTER COLUMN cohort_months SET NOT NULL;")

    # 3) (week_start, cohort_months) ìœ ë‹ˆí¬ ë³´ì¥
    #    PK ì¶”ê°€ê°€ ì‹¤íŒ¨(ê¸°ì¡´ PK ì¡´ì¬ ë“±)í•´ë„, ìœ ë‹ˆí¬ ì¸ë±ìŠ¤ëŠ” ë°˜ë“œì‹œ ìƒì„±
    try:
        hook.run("""
        ALTER TABLE kpis.weekly_actuals
        ADD CONSTRAINT weekly_actuals_pkey
        PRIMARY KEY (week_start, cohort_months);
        """)
    except Exception:
        pass  # ì´ë¯¸ PKê°€ ìˆìœ¼ë©´ ë¬´ì‹œ

    hook.run("""
    CREATE UNIQUE INDEX IF NOT EXISTS weekly_actuals_week_cohort_uniq
    ON kpis.weekly_actuals(week_start, cohort_months);
    """)



def _ensure_km_tables(hook: PostgresHook):
    # km_models (kpis ìŠ¤í‚¤ë§ˆ ê°•ì œ)
    hook.run("""
    CREATE TABLE IF NOT EXISTS kpis.km_models (
      fit_window_start date,
      fit_window_end   date,
      time_unit        varchar(16),
      cohort_months    integer,
      time_k           integer
    );
    """)
    # ëˆ„ë½ ì»¬ëŸ¼ ë³´ê°•
    hook.run("ALTER TABLE kpis.km_models ADD COLUMN IF NOT EXISTS s double precision;")
    hook.run("ALTER TABLE kpis.km_models ADD COLUMN IF NOT EXISTS q double precision;")
    hook.run("ALTER TABLE kpis.km_models ADD COLUMN IF NOT EXISTS h double precision;")

    # model_versionsë„ kpisë¡œ
    hook.run("""
    CREATE TABLE IF NOT EXISTS kpis.model_versions (
      fit_window_start date,
      fit_window_end   date,
      time_unit        varchar(16),
      horizon_weeks    integer,
      status           varchar(16),
      created_at       timestamptz DEFAULT now(),
      created_by       varchar(64),
      notes            text,
      PRIMARY KEY (fit_window_start, fit_window_end, time_unit)
    );
    """)


def _monday(d: pd.Timestamp) -> pd.Timestamp:
    return d - pd.Timedelta(days=d.weekday())

# -----------------------------
# DAG
# -----------------------------
@dag(
    dag_id="km_weekly_full",
    schedule="59 23 * * SUN",  # ë§¤ì£¼ ì¼ìš”ì¼ 23:59
    start_date=datetime(2025, 1, 1, tzinfo=SEOUL),
    catchup=False,
    default_args={"retries": 2, "retry_delay": timedelta(minutes=10)},
    tags=["KM_calculator", "weekly", "lvt_log"],
)
def km_weekly_full():

    @task()
    def compute_window():
        now_kst = pendulum.now(SEOUL)
        week_start, week_end = _week_bounds_kst(now_kst)
        # ì¬í•™ìŠµ ì°½: ìµœê·¼ FIT_MONTHSê°œì›” (ì›”ìš”ì¼ ì •ë ¬)
        fit_end = pd.to_datetime(week_end)
        fit_start = (fit_end - pd.DateOffset(months=FIT_MONTHS)).normalize()
        fit_start = _monday(fit_start)  # ì°½ ì‹œì‘ì„ ì›”ìš”ì¼ë¡œ ì •ë ¬(ì„ íƒ)
        return {
            "week_start": week_start,   # ì›”ìš”ì¼
            "week_end": week_end,       # ì¼ìš”ì¼
            "fit_start": fit_start.date().isoformat(),
            "fit_end": week_end,        # as-ofì™€ ë™ì¼ ì£¼ ì¢…ë£Œì¼
            "horizon_weeks": HORIZON_WEEKS,
        }

    @task()
    def insert_new(window: dict):
        """
        new_lecture â†’ lvt_log INSERT (ê°•ì œ ê²¹ì¹¨ ì¢…ë£Œ ë²„ì „)
        - ì´ë²ˆ ì£¼(start_date âˆˆ [week_start, week_end]) ì‹ ê·œë§Œ
        - ë™ì¼ lectureì— ì—´ë¦° episodeê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ë‹«ê³ (end_date = min(start_date-1, week_end)), ìƒˆ episode ì‚½ì…
        - ë©±ë“±ì„±: ON CONFLICT (lecture_vt_no, episode_no) DO NOTHING
        - ë°˜í™˜: ì‹¤ì œ insert ìˆ˜, ìŠ¤í‚µ ì‚¬ìœ  ìƒ˜í”Œ
        """
        hook = PostgresHook(postgres_conn_id=CONN_ID)

        sql = """
        WITH params AS (
          SELECT %(week_start)s::date AS week_start, %(week_end)s::date AS week_end
        ),
        new_src AS (
          SELECT
            n.lecture_vt_no,
            n.student_user_no,
            n.fst_months,
            n.start_date::date AS start_date,
            n.tutoring_state
          FROM kpis.new_lecture n, params p
          WHERE n.start_date::date BETWEEN p.week_start AND p.week_end
        ),

        /* 1) ê²¹ì¹¨ ë¬´ì¡°ê±´ ì¢…ë£Œ:
              - ê°™ì€ lectureì— ì—´ë¦° ì—í”¼ì†Œë“œê°€ ìˆìœ¼ë©´ ì „ë¶€ ë‹«ìŒ
              - end_date = LEAST(start_date-1, week_end) */
        closed AS (
          UPDATE kpis.lvt_log l
          SET end_date  = LEAST((s.start_date - INTERVAL '1 day')::date, (SELECT week_end FROM params)),
              updated_at = NOW()
          FROM new_src s
          WHERE l.lecture_vt_no = s.lecture_vt_no
            AND l.end_date IS NULL
          RETURNING l.lecture_vt_no
        ),

        /* 2) (ë‹«ì€ ì´í›„) lectureë³„ ìƒíƒœ ì¬ì§‘ê³„ */
        state AS (
          SELECT
            l.lecture_vt_no,
            MAX(l.episode_no) AS max_ep,
            BOOL_OR(l.end_date IS NULL) AS has_open
          FROM kpis.lvt_log l
          GROUP BY l.lecture_vt_no
        ),

        /* 3) ì‚½ì… í›„ë³´ ì‚°ì¶œ */
        cand AS (
          SELECT
            n.lecture_vt_no,
            n.student_user_no,
            n.fst_months,
            n.start_date,
            n.tutoring_state,
            COALESCE(s.max_ep, 0) + 1 AS next_ep,
            COALESCE(s.has_open, FALSE) AS has_open
          FROM new_src n
          LEFT JOIN state s ON s.lecture_vt_no = n.lecture_vt_no
        ),

        /* 4) ì‚½ì… */
        ins AS (
          INSERT INTO kpis.lvt_log (
            lecture_vt_no, episode_no, student_user_no, fst_months,
            start_date, end_date, tutoring_state, created_at, updated_at
          )
          SELECT
            c.lecture_vt_no,
            c.next_ep AS episode_no,
            c.student_user_no,
            c.fst_months,
            c.start_date,
            NULL AS end_date,
            c.tutoring_state,
            NOW(), NOW()
          FROM cand c
          WHERE c.has_open = FALSE
          ON CONFLICT (lecture_vt_no, episode_no) DO NOTHING
          RETURNING lecture_vt_no
        )

        SELECT
          (SELECT COUNT(*)::int FROM ins)           AS inserted_rows,
          (SELECT COUNT(*)::int FROM new_src)       AS src_rows,
          (SELECT COUNT(*)::int FROM closed)        AS closed_rows,
          (SELECT COUNT(*)::int FROM cand WHERE has_open = TRUE) AS skipped_open_rows;
        """

        inserted_rows, src_rows, closed_rows, skipped_open_rows = hook.get_first(sql, parameters=window)

        # ğŸ” ì¶”ê°€ ì§„ë‹¨: ìŠ¤í‚µ ëŒ€ìƒ ìƒ˜í”Œ(ì—´ë¦° ì—í”¼ì†Œë“œê°€ ë‚¨ì•„ì„œ ëª» ë“¤ì–´ê°„ ì¼€ì´ìŠ¤ í™•ì¸)
        skip_sql = """
        WITH params AS (SELECT %(week_start)s::date AS ws, %(week_end)s::date AS we),
        new_src AS (
          SELECT n.lecture_vt_no, n.student_user_no, n.fst_months, n.start_date::date AS start_date
          FROM kpis.new_lecture n, params p
          WHERE n.start_date::date BETWEEN p.ws AND p.we
        ),
        state AS (
          SELECT l.lecture_vt_no, BOOL_OR(l.end_date IS NULL) AS has_open
          FROM kpis.lvt_log l
          GROUP BY l.lecture_vt_no
        )
        SELECT ns.lecture_vt_no, ns.start_date, s.has_open
        FROM new_src ns
        LEFT JOIN state s ON s.lecture_vt_no = ns.lecture_vt_no
        WHERE COALESCE(s.has_open, FALSE) = TRUE
        ORDER BY ns.start_date, ns.lecture_vt_no
        LIMIT 50;
        """
        skipped_samples = hook.get_records(skip_sql, parameters=window)

        return {
            "inserted_new": int(inserted_rows or 0),
            "source_rows": int(src_rows or 0),
            "closed_rows": int(closed_rows or 0),
            "skipped_open_rows": int(skipped_open_rows or 0),
            "skipped_samples": skipped_samples,  # [(lecture_vt_no, start_date, has_open), ...]
        }



    @task()
    def update_pause(window: dict):
        """
        pause_lecture â†’ lvt_log UPDATE
        - ì´ë²ˆ ì£¼(end_date âˆˆ [week_start, week_end]) ì¤‘ë‹¨ë§Œ
        - ì—´ë¦° episode(end_date IS NULL)ë§Œ ë‹«ìŒ
        - start_dateë³´ë‹¤ ì•ì„¤ ìˆ˜ ì—†ë„ë¡ GREATEST
        """
        hook = PostgresHook(postgres_conn_id=CONN_ID)
        sql = """
        WITH params AS (
          SELECT %(week_start)s::date AS week_start, %(week_end)s::date AS week_end
        ),
        pause_src AS (
          SELECT
            p.lecture_vt_no,
            p.end_date::date AS pause_date,
            p.tutoring_state
          FROM kpis.pause_lecture p, params par
          WHERE p.end_date::date BETWEEN par.week_start AND par.week_end
        )
        UPDATE kpis.lvt_log l
        SET
          end_date       = GREATEST(p.pause_date, l.start_date),
          tutoring_state = COALESCE(p.tutoring_state, l.tutoring_state),
          updated_at     = NOW()
        FROM pause_src p
        WHERE p.lecture_vt_no = l.lecture_vt_no
          AND l.end_date IS NULL;
        """
        hook.run(sql, parameters=window)
        # í†µê³„
        cnt_sql = """
        WITH p AS (SELECT %(week_start)s::date AS ws, %(week_end)s::date AS we)
        SELECT COUNT(*) FROM kpis.lvt_log, p WHERE end_date BETWEEN p.ws AND p.we;
        """
        cnt = hook.get_first(cnt_sql, parameters=window)[0]
        return {"updated_pause": int(cnt)}

    @task()
    def aggregate_weekly_actuals(window: dict):
        """
        lvt_log â†’ weekly_actuals ì½”í˜¸íŠ¸ë³„ ì§‘ê³„/ì—…ì„œíŠ¸
        ê¸°ì¤€: ì›”~ì¼(Asia/Seoul)
        ì£¼ì˜: weekly_actuals PK = (week_start, cohort_months)
        """
        hook = PostgresHook(postgres_conn_id=CONN_ID)
        _ensure_weekly_actuals(hook)  # ì´ë¯¸ (week_start, cohort_months) PK ë³´ì¥í•˜ëŠ” ë²„ì „

        sql = """
        WITH p AS (
        SELECT %(week_start)s::date AS week_start, %(week_end)s::date AS week_end
        ),
        cohorts AS (
        SELECT 1 AS cohort_months UNION ALL
        SELECT 3 UNION ALL
        SELECT 6 UNION ALL
        SELECT 12
        ),
        agg AS (
        SELECT
            p.week_start,
            c.cohort_months,
            COALESCE(SUM(CASE WHEN l.start_date BETWEEN p.week_start AND p.week_end THEN 1 ELSE 0 END), 0) AS new_actual,
            COALESCE(SUM(CASE WHEN l.end_date   BETWEEN p.week_start AND p.week_end THEN 1 ELSE 0 END), 0) AS pause_actual
        FROM p
        CROSS JOIN cohorts c
        LEFT JOIN kpis.lvt_log l
            ON l.fst_months = c.cohort_months
        GROUP BY p.week_start, c.cohort_months
        )
        INSERT INTO kpis.weekly_actuals (week_start, cohort_months, new_actual, pause_actual, source, closed_at)
        SELECT
        a.week_start, a.cohort_months, a.new_actual, a.pause_actual, 'lvt_log', NOW()
        FROM agg a
        ON CONFLICT (week_start, cohort_months) DO UPDATE
        SET new_actual = EXCLUDED.new_actual,
            pause_actual = EXCLUDED.pause_actual,
            source      = EXCLUDED.source,
            closed_at   = NOW();
        """
        hook.run(sql, parameters=window)
        return {"status": "ok"}


    @task()
    def retrain_km(window: dict):
        """
        lvt_log ê¸°ë°˜ KM ì¬í•™ìŠµ
        - í•™ìŠµ ì°½: [fit_start, fit_end] ì‚¬ì´ start_date
        - as_of = week_end (ì¼ìš”ì¼)
        - ì½”í˜¸íŠ¸: fst_months in (1,3,6,12)
        - ì €ì¥: km_models(S,q,h), model_versions upsert
        """
        hook = PostgresHook(postgres_conn_id=CONN_ID)
        _ensure_km_tables(hook)

        # ----- ë°ì´í„° ë¡œë“œ
        eng = hook.get_sqlalchemy_engine()
        fit_start = pd.to_datetime(window["fit_start"])
        fit_end   = pd.to_datetime(window["fit_end"])
        as_of = pd.Timestamp(window["week_end"]).normalize()
        horizon   = int(window["horizon_weeks"])
        

        df = pd.read_sql(
            """
            SELECT lecture_vt_no, student_user_no, fst_months, start_date, end_date
            FROM kpis.lvt_log
            WHERE start_date BETWEEN %(s)s AND %(e)s
              AND fst_months IN (1,3,6,12)
            """,
            eng,
            params={"s": fit_start, "e": fit_end},
        )
        if df.empty:
            return {"status": "no_data"}
        
        # ---- ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ ì „ë¶€ tz-naive Timestampë¡œ ê°•ì œ ë³€í™˜ ----
        def _as_naive_ts(s: pd.Series) -> pd.Series:
            s = pd.to_datetime(s, errors="coerce")              # object(date) â†’ datetime64[ns] ë˜ëŠ” datetime64[ns, tz]
            tz = getattr(s.dtype, "tz", None)
            if tz is not None:                                   # tz-aware â†’ tz-naive
                s = s.dt.tz_convert(None)
            return s.dt.normalize()       

        df["start_date"] = _as_naive_ts(df["start_date"])
        df["end_date"]   = _as_naive_ts(df["end_date"])

        print(df[["start_date","end_date"]].dtypes)  # ë‘˜ ë‹¤ datetime64[ns] ì—¬ì•¼ í•©ë‹ˆë‹¤.
        print(type(as_of))                           # <class 'pandas._libs.tslibs.timestamps.Timestamp'>


        # ----- KMìš© í‘œë³¸ ë³€í™˜
        def weeks_between(a, b) -> int:
            return max(0, (pd.to_datetime(b) - pd.to_datetime(a)).days // 7)

        # event: end_dateê°€ ìˆê³  as_of ì´ì „/ë™ì¼ì´ë©´ 1, ê·¸ ì™¸ 0(ê²€ì—´)
        event = (df["end_date"].notna()) & (df["end_date"] <= as_of)
        df["event"] = np.where(event, 1, 0).astype(int)
        df["survival_time"] = np.where(
            df["event"] == 1,
            [weeks_between(s, e) for s, e in zip(df["start_date"], df["end_date"])],
            [weeks_between(s, as_of) for s in df["start_date"]],
        )

        df = df[df["survival_time"] >= 0].copy()
        if df.empty:
            return {"status": "no_samples"}

        # ----- ì •ìˆ˜ì‹œì  Kaplanâ€“Meier (ì£¼ ë‹¨ìœ„) êµ¬í˜„
        def km_discrete(times: np.ndarray, events: np.ndarray, horizon_weeks: int):
            """
            times: ìƒì¡´ì‹œê°„(ì£¼) ì •ìˆ˜, events: 1=ì´ë²¤íŠ¸, 0=ê²€ì—´
            ë°˜í™˜: S[0..H], q[0..H], h[0..H]
            """
            times = times.astype(int)
            H = horizon_weeks
            # ì£¼ì°¨ë³„ ì´ë²¤íŠ¸/ê²€ì—´ ì¹´ìš´íŠ¸
            max_t = max(times.max(), H)
            d = np.zeros(max_t + 1, dtype=int)  # events at t
            c = np.zeros(max_t + 1, dtype=int)  # censored at t
            for t, e in zip(times, events):
                if e == 1:
                    d[t] += 1
                else:
                    c[t] += 1

            N = len(times)
            S = np.zeros(H + 1, dtype=float)
            q = np.zeros(H + 1, dtype=float)
            h = np.zeros(H + 1, dtype=float)

            S[0] = 1.0
            n_at_risk = N  # t=0 ì§ì „ ìœ„í—˜ì§‘ë‹¨
            # t=0ì€ ì •ì˜ìƒ q=0, h=0
            for t in range(1, H + 1):
                if n_at_risk > 0:
                    h[t] = min(1.0, max(0.0, d[t] / n_at_risk))
                    S[t] = S[t-1] * (1.0 - h[t])
                    q[t] = max(0.0, S[t-1] - S[t])  # Î”S
                    # ë‹¤ìŒ ì‹œì  ìœ„í—˜ì§‘ë‹¨ ì—…ë°ì´íŠ¸
                    n_at_risk = n_at_risk - d[t] - c[t]
                    if n_at_risk < 0:
                        n_at_risk = 0
                else:
                    S[t] = S[t-1]
                    q[t] = 0.0
                    h[t] = 0.0
            return S, q, h

        rows = []
        for c_val, g in df.groupby("fst_months"):
            times = g["survival_time"].to_numpy()
            events = g["event"].to_numpy()
            S, q, h = km_discrete(times, events, horizon)

            for k in range(0, horizon + 1):
                rows.append({
                    "fit_window_start": fit_start,
                    "fit_window_end": fit_end,
                    "time_unit": "week",
                    "cohort_months": int(c_val),
                    "time_k": int(k),
                    "s": float(S[k]),
                    "q": float(q[k]),   # Î”S(k)
                    "h": float(h[k]),   # hazard(k)
                })

        df_km_out = pd.DataFrame(rows).sort_values(["cohort_months", "time_k"])

        # ----- ì €ì¥ (í•­ìƒ kpis.km_models ì‚¬ìš©)
        with hook.get_conn() as conn, conn.cursor() as cur:
            cur.execute(
                """
                DELETE FROM kpis.km_models
                WHERE fit_window_start=%s AND fit_window_end=%s AND time_unit='week'
                """,
                (fit_start, fit_end)
            )
            conn.commit()

        # Pandas â†’ SQL: ìŠ¤í‚¤ë§ˆ ì§€ì • + ì»¬ëŸ¼ dtype ì •ë¦¬(ë‚ ì§œëŠ” dateë¡œ ë‹¤ìš´ìºìŠ¤íŠ¸ ê¶Œì¥)
        df_km_out = df_km_out.copy()
        df_km_out["fit_window_start"] = pd.to_datetime(df_km_out["fit_window_start"]).dt.date
        df_km_out["fit_window_end"]   = pd.to_datetime(df_km_out["fit_window_end"]).dt.date

        df_km_out.to_sql(
            "km_models",
            hook.get_sqlalchemy_engine(),
            schema="kpis",              # âœ… ì¤‘ìš”
            if_exists="append",
            index=False,
        )

        with hook.get_conn() as conn, conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO kpis.model_versions
                (fit_window_start, fit_window_end, time_unit, horizon_weeks, status, created_by, notes)
                VALUES
                (%s, %s, 'week', %s, 'active', %s, %s)
                ON CONFLICT (fit_window_start, fit_window_end, time_unit)
                DO UPDATE SET
                horizon_weeks = EXCLUDED.horizon_weeks,
                status        = 'active',
                created_at    = now(),
                created_by    = EXCLUDED.created_by,
                notes         = EXCLUDED.notes
                """,
                (fit_start, fit_end, horizon, "airflow:weekly", f"Weekly retrain as_of={window['week_end']}")
            )
            conn.commit()


        return {"status": "ok", "rows": int(len(df_km_out))}

    @task()
    def promote_model(_retrain_res: dict):
        """í•„ìš”ì‹œ ì¶”ê°€ ë¡œì§(ì˜ˆ: êµ¬ ëª¨ë¸ status='archived') â€” ì—¬ê¸°ì„œëŠ” íŒ¨ìŠ¤"""
        return {"status": "ok"}

    # ---- ì˜ì¡´ì„± ----
    w = compute_window()
    n = insert_new(w)
    p = update_pause(w)
    a = aggregate_weekly_actuals(w)
    r = retrain_km(w)

    p >> n >> a >> r >> promote_model(r)

km_weekly_full()
